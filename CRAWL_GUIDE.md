# ğŸ•·ï¸ HÆ°á»›ng Dáº«n Crawl Articles

## ğŸ“‹ Tá»•ng Quan

Service crawl sá»­ dá»¥ng **SeleniumBase** Ä‘á»ƒ crawl articles tá»« [sermitsiaq.ag](https://www.sermitsiaq.ag) vÃ  lÆ°u vÃ o PostgreSQL database.

## ğŸ–¼ï¸ Vá» HÃ¬nh áº¢nh

**KhÃ´ng download hÃ¬nh áº£nh** - chá»‰ lÆ°u link tá»« website gá»‘c:
- âœ… Tiáº¿t kiá»‡m storage
- âœ… ÄÆ¡n giáº£n hÆ¡n
- âœ… LuÃ´n cÃ³ hÃ¬nh áº£nh má»›i nháº¥t tá»« CDN cá»§a há»
- âœ… KhÃ´ng cáº§n quáº£n lÃ½ file upload

HÃ¬nh áº£nh Ä‘Æ°á»£c lÆ°u trong `image_data` (JSON) vá»›i cÃ¡c link:
- `desktop_webp`, `desktop_jpeg`
- `mobile_webp`, `mobile_jpeg`
- `fallback`

## ğŸš€ CÃ i Äáº·t

### 1. CÃ i Ä‘áº·t dependencies

```bash
cd flask
pip install -r requirements.txt
```

### 2. CÃ i Ä‘áº·t Chrome/Chromium (cho SeleniumBase)

**Ubuntu/Debian:**
```bash
sudo apt-get update
sudo apt-get install -y chromium-browser
```

**macOS:**
```bash
brew install --cask google-chrome
```

**Hoáº·c dÃ¹ng Chromium:**
```bash
brew install --cask chromium
```

## ğŸ“ Sá»­ Dá»¥ng

### Crawl section erhverv (máº·c Ä‘á»‹nh)

```bash
python3 scripts/crawl_articles.py erhverv
```

### Crawl vá»›i tÃ¹y chá»n

```bash
# Crawl 100 articles
python3 scripts/crawl_articles.py erhverv --max-articles 100

# Crawl vá»›i browser visible (Ä‘á»ƒ debug)
python3 scripts/crawl_articles.py erhverv --no-headless

# Crawl section khÃ¡c
python3 scripts/crawl_articles.py samfund
python3 scripts/crawl_articles.py kultur
python3 scripts/crawl_articles.py sport
python3 scripts/crawl_articles.py job
```

### Crawl tá»« Python code

```python
from app import app
from services.crawl_service import SermitsiaqCrawler

with app.app_context():
    crawler = SermitsiaqCrawler()
    
    try:
        crawler.start_browser(headless=True)
        result = crawler.crawl_section(
            section_url='https://www.sermitsiaq.ag/tag/erhverv',
            section_name='erhverv',
            max_articles=50
        )
        print(result)
    finally:
        crawler.close_browser()
```

## ğŸ“Š Dá»¯ Liá»‡u ÄÆ°á»£c Crawl

Má»—i article sáº½ cÃ³:

- âœ… **element_guid**: GUID duy nháº¥t (dÃ¹ng Ä‘á»ƒ check duplicate)
- âœ… **title**: TiÃªu Ä‘á»
- âœ… **slug**: URL slug
- âœ… **url**: URL Ä‘áº§y Ä‘á»§
- âœ… **k5a_url**: URL cho K5A
- âœ… **section**: Section (erhverv, samfund, kultur, sport, job)
- âœ… **published_date**: NgÃ y publish
- âœ… **is_paywall**: CÃ³ pháº£i paywall khÃ´ng
- âœ… **image_data**: ThÃ´ng tin hÃ¬nh áº£nh (JSON) - **chá»‰ link, khÃ´ng download**
- âœ… **display_order**: Thá»© tá»± hiá»ƒn thá»‹ (0, 1, 2, ...) - **quan trá»ng cho pattern 2-3-2-3-2-3...**

## ğŸ”„ Logic Crawl

1. **Má»Ÿ browser** vá»›i SeleniumBase (headless mode)
2. **Navigate** Ä‘áº¿n section URL (vÃ­ dá»¥: `https://www.sermitsiaq.ag/tag/erhverv`)
3. **Scroll** Ä‘á»ƒ load thÃªm articles (lazy loading)
4. **Parse HTML** Ä‘á»ƒ extract article data:
   - TÃ¬m táº¥t cáº£ `<article>` elements
   - Extract: title, URL, image, paywall, date, etc.
5. **LÆ°u vÃ o database**:
   - Náº¿u article Ä‘Ã£ tá»“n táº¡i (theo `element_guid`) â†’ **Update**
   - Náº¿u chÆ°a tá»“n táº¡i â†’ **Create má»›i**
6. **Set `display_order`** Ä‘á»ƒ match pattern 2-3-2-3-2-3...

## ğŸ“ Cáº¥u TrÃºc Files

```
flask/
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ crawl_service.py      # Main crawl service
â”‚   â”œâ”€â”€ article_parser.py     # Parser HTML
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ crawl_articles.py     # Script cháº¡y crawl
â””â”€â”€ CRAWL_GUIDE.md            # File nÃ y
```

## âš™ï¸ Cáº¥u HÃ¬nh

### Database Connection

Äáº£m báº£o `.env` cÃ³ `DATABASE_URL`:

```env
DATABASE_URL=postgresql://flask_user:password@localhost/flask_news
```

### Crawl Settings

Trong `crawl_service.py`, cÃ³ thá»ƒ tÃ¹y chá»‰nh:
- `max_scrolls`: Sá»‘ láº§n scroll tá»‘i Ä‘a (default: 10)
- `scroll_pause`: Thá»i gian chá» giá»¯a cÃ¡c láº§n scroll (default: 2 giÃ¢y)

## ğŸ› Troubleshooting

### Browser khÃ´ng khá»Ÿi Ä‘á»™ng

```bash
# Kiá»ƒm tra Chrome/Chromium
which google-chrome
which chromium-browser

# CÃ i Ä‘áº·t náº¿u chÆ°a cÃ³
sudo apt-get install chromium-browser  # Ubuntu/Debian
brew install --cask google-chrome      # macOS
```

### Lá»—i import

```bash
# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# Kiá»ƒm tra Python path
python3 -c "import sys; print(sys.path)"
```

### Database connection error

```bash
# Kiá»ƒm tra .env
cat .env | grep DATABASE_URL

# Test connection
python3 -c "from app import app, db; app.app_context().push(); print('âœ… Connected!')"
```

### KhÃ´ng crawl Ä‘Æ°á»£c articles

1. **Kiá»ƒm tra network**: Äáº£m báº£o cÃ³ thá»ƒ truy cáº­p `https://www.sermitsiaq.ag`
2. **Cháº¡y vá»›i `--no-headless`**: Äá»ƒ xem browser cÃ³ load Ä‘Æ°á»£c khÃ´ng
3. **Kiá»ƒm tra HTML structure**: Website cÃ³ thá»ƒ Ä‘Ã£ thay Ä‘á»•i cáº¥u trÃºc

## ğŸ“ LÆ°u Ã

1. **Rate limiting**: TrÃ¡nh crawl quÃ¡ nhanh Ä‘á»ƒ khÃ´ng bá»‹ block
2. **Respect robots.txt**: NÃªn check robots.txt trÆ°á»›c khi crawl
3. **Update logic**: Náº¿u website thay Ä‘á»•i cáº¥u trÃºc HTML, cáº§n update parser
4. **Display order**: Quan trá»ng Ä‘á»ƒ match pattern 2-3-2-3-2-3... trong UI

## âœ… Sau Khi Crawl

Sau khi crawl xong, articles sáº½ tá»± Ä‘á»™ng hiá»ƒn thá»‹ trÃªn trang chá»§ (`/`) vá»›i pattern 2-3-2-3-2-3...

Xem articles:
```bash
# Query tá»« database
python3 -c "from app import app, db; from database import Article; app.app_context().push(); print(f'Total articles: {Article.query.count()}')"
```

