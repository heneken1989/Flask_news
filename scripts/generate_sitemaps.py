"""
Script ƒë·ªÉ generate 3 sitemap ri√™ng cho 3 ng√¥n ng·ªØ:
- sitemap.xml (EN)
- sitemap-DK.xml (DA)
- sitemap-KL.xml (KL)

Usage:
    python scripts/generate_sitemaps.py
    python scripts/generate_sitemaps.py --output-dir /path/to/output
"""
import sys
import os
import argparse
import re
from datetime import datetime
from urllib.parse import urlparse, urlunparse
import xml.etree.ElementTree as ET

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app import app
from database import db, Article


def extract_image_id_from_image_data(image_data):
    """
    Extract imageId t·ª´ image_data ƒë·ªÉ t·∫°o URL image
    C√≥ th·ªÉ l·∫•y t·ª´:
    1. URL image c√≥ ch·ª©a imageId (v√≠ d·ª•: ?imageId=2333823)
    2. element_guid (n·∫øu c√≥)
    
    Args:
        image_data: dict ch·ª©a image data
        
    Returns:
        imageId (str) ho·∫∑c None
    """
    if not image_data:
        return None
    
    # Th·ª≠ extract t·ª´ URL image
    image_urls = [
        image_data.get('desktop_webp'),
        image_data.get('desktop_jpeg'),
        image_data.get('mobile_webp'),
        image_data.get('mobile_jpeg'),
        image_data.get('fallback')
    ]
    
    for url in image_urls:
        if not url:
            continue
        
        # T√¨m imageId trong URL
        match = re.search(r'[?&]imageId=(\d+)', url)
        if match:
            return match.group(1)
        
        # Ho·∫∑c extract t·ª´ path (v√≠ d·ª•: /2333823.webp)
        match = re.search(r'/(\d+)\.(webp|jpg|jpeg)', url)
        if match:
            return match.group(1)
    
    # Fallback: th·ª≠ d√πng element_guid n·∫øu c√≥ (nh∆∞ng kh√¥ng ch·∫Øc ch·∫Øn)
    # element_guid th∆∞·ªùng l√† UUID, kh√¥ng ph·∫£i imageId
    # return image_data.get('element_guid')
    
    return None


def get_article_url(article, language='en', base_domain='www.sermitsiaq.com'):
    """
    L·∫•y URL c·ªßa article theo ng√¥n ng·ªØ
    
    Args:
        article: Article object
        language: Language code ('en', 'da', 'kl')
        base_domain: Domain ƒë·ªÉ t·∫°o URL (default: www.sermitsiaq.com)
        
    Returns:
        Full URL string
    """
    url_to_use = None
    
    if language == 'en' and article.published_url_en:
        url_to_use = article.published_url_en
    elif article.published_url:
        url_to_use = article.published_url
    else:
        return None
    
    if not url_to_use:
        return None
    
    # Parse URL ƒë·ªÉ l·∫•y path
    parsed = urlparse(url_to_use)
    path_only = parsed.path
    
    # T·∫°o URL m·ªõi v·ªõi domain m·ªõi
    new_url = urlunparse((
        'https',
        base_domain,
        path_only,
        parsed.params,
        parsed.query,
        parsed.fragment
    ))
    
    return new_url


def format_lastmod(published_date):
    """
    Format published_date th√†nh format: 2026-01-22T00:00+01:00
    
    Args:
        published_date: datetime object ho·∫∑c string
        
    Returns:
        Formatted date string
    """
    if not published_date:
        return None
    
    if isinstance(published_date, datetime):
        # Format: 2026-01-22T00:00+01:00
        return published_date.strftime('%Y-%m-%dT00:00+01:00')
    else:
        # N·∫øu l√† string, th·ª≠ parse
        try:
            if isinstance(published_date, str):
                # Th·ª≠ parse ISO format
                dt = datetime.fromisoformat(published_date.replace('Z', '+00:00'))
                return dt.strftime('%Y-%m-%dT00:00+01:00')
        except:
            pass
        
        # Fallback: l·∫•y 10 k√Ω t·ª± ƒë·∫ßu (YYYY-MM-DD)
        date_str = str(published_date)[:10]
        if len(date_str) == 10:
            return f"{date_str}T00:00+01:00"
    
    return None


def generate_sitemap(language='en', output_file=None, base_domain='www.sermitsiaq.com'):
    """
    Generate sitemap.xml cho m·ªôt ng√¥n ng·ªØ
    
    Args:
        language: Language code ('en', 'da', 'kl')
        output_file: Path to output file (None = return XML string)
        base_domain: Domain ƒë·ªÉ t·∫°o URL (default: sermitsiaq.com)
        
    Returns:
        XML string n·∫øu output_file=None, ho·∫∑c None n·∫øu write to file
    """
    with app.app_context():
        # Query articles theo language
        articles = Article.query.filter_by(
            language=language,
            is_temp=False
        ).filter(
            Article.published_url.isnot(None),
            Article.published_url != ''
        ).order_by(
            Article.published_date.desc().nullslast()
        ).all()
        
        print(f"\nüìã Generating sitemap for {language.upper()}...")
        print(f"   Found {len(articles)} articles")
        
        # Create XML root
        root = ET.Element('urlset')
        root.set('xmlns', 'http://www.sitemaps.org/schemas/sitemap/0.9')
        root.set('xmlns:image', 'http://www.google.com/schemas/sitemap-image/1.1')
        
        url_count = 0
        image_count = 0
        
        for article in articles:
            # Get article URL
            article_url = get_article_url(article, language=language, base_domain=base_domain)
            if not article_url:
                continue
            
            # Create url element
            url_elem = ET.SubElement(root, 'url')
            
            # Loc
            loc_elem = ET.SubElement(url_elem, 'loc')
            loc_elem.text = article_url
            
            # Lastmod
            lastmod = format_lastmod(article.published_date)
            if lastmod:
                lastmod_elem = ET.SubElement(url_elem, 'lastmod')
                lastmod_elem.text = lastmod
            
            # Image - ∆Øu ti√™n l·∫•y link t·ª´ domain c·ªßa ch√∫ng ta
            if article.image_data:
                image_url = None
                
                # ∆Øu ti√™n 1: Ki·ªÉm tra xem c√≥ URL t·ª´ domain c·ªßa ch√∫ng ta kh√¥ng
                # Check theo th·ª© t·ª±: desktop_webp, fallback, desktop_jpeg, mobile_webp, mobile_jpeg
                for key in ['desktop_webp', 'fallback', 'desktop_jpeg', 'mobile_webp', 'mobile_jpeg']:
                    url = article.image_data.get(key)
                    if url:
                        # Check xem c√≥ ph·∫£i URL t·ª´ domain c·ªßa ch√∫ng ta kh√¥ng
                        # (ch·ª©a sermitsiaq.com v√† static/uploads/images, ho·∫∑c kh√¥ng ch·ª©a image.sermitsiaq.ag)
                        if ('sermitsiaq.com' in url and 'static/uploads/images' in url) or \
                           ('sermitsiaq.com' in url and 'image.sermitsiaq.ag' not in url):
                            # ƒê√¢y l√† URL t·ª´ domain c·ªßa ch√∫ng ta
                            image_url = url
                            break
                
                # ∆Øu ti√™n 2: N·∫øu kh√¥ng c√≥ URL t·ª´ domain c·ªßa ch√∫ng ta, d√πng URL t·ª´ trang g·ªëc
                if not image_url:
                    image_id = extract_image_id_from_image_data(article.image_data)
                    if image_id:
                        # Fallback v·ªÅ URL g·ªëc t·ª´ image.sermitsiaq.ag
                        image_url = f'https://image.sermitsiaq.ag?imageId={image_id}&format=webp&width=1200'
                
                if image_url:
                    image_elem = ET.SubElement(url_elem, 'image:image')
                    image_loc_elem = ET.SubElement(image_elem, 'image:loc')
                    image_loc_elem.text = image_url
                    image_count += 1
            
            url_count += 1
        
        print(f"   ‚úÖ Generated {url_count} URLs, {image_count} images")
        
        # Create XML string
        ET.indent(root, space='  ')
        xml_str = ET.tostring(root, encoding='utf-8', xml_declaration=True)
        
        # Write to file or return
        if output_file:
            with open(output_file, 'wb') as f:
                f.write(xml_str)
            print(f"   üíæ Saved to: {output_file}")
            return None
        else:
            return xml_str


def main():
    parser = argparse.ArgumentParser(
        description='Generate sitemap.xml files for 3 languages',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Generate all 3 sitemaps in current directory
  python scripts/generate_sitemaps.py
  
  # Generate to specific output directory
  python scripts/generate_sitemaps.py --output-dir /path/to/output
  
  # Generate only one language
  python scripts/generate_sitemaps.py --language en
        """
    )
    
    parser.add_argument('--output-dir', '-o', default='.',
                        help='Output directory for sitemap files (default: current directory)')
    parser.add_argument('--language', '-l', choices=['en', 'da', 'kl'],
                        help='Generate sitemap for specific language only')
    parser.add_argument('--domain', '-d', default='www.sermitsiaq.com',
                        help='Base domain for URLs (default: www.sermitsiaq.com)')
    
    args = parser.parse_args()
    
    # Create output directory if not exists
    os.makedirs(args.output_dir, exist_ok=True)
    
    languages = [args.language] if args.language else ['en', 'da', 'kl']
    file_names = {
        'en': 'sitemap.xml',
        'da': 'sitemap-DK.xml',
        'kl': 'sitemap-KL.xml'
    }
    
    for lang in languages:
        output_file = os.path.join(args.output_dir, file_names[lang])
        generate_sitemap(
            language=lang,
            output_file=output_file,
            base_domain=args.domain
        )
    
    print(f"\n{'='*60}")
    print(f"‚úÖ All sitemaps generated successfully!")
    print(f"{'='*60}\n")


if __name__ == '__main__':
    main()

